from microphone import Microphone, Stream, CHUNK, RATE, FORMAT, CHANNELS
from multiprocessing import Queue, Process
from typing import List, Any
import pyaudio
import wave

def consume_frames([head] :: tail, q):
  q.put(head)
  consume_frames(tail, q)

def listen(mic: Microphone, q: Queue):
  stream = mic.open_stream()
  consume_frames(stream.frames(), q)

def read_frames(q, acc, num_sec if num_sec <= 0) = acc

@addpattern(read_frames)
def read_frames(q: Queue, acc: List[str], num_sec: int) -> List[str] = read_frames(q, acc + [q.get()], num_sec - (CHUNK / RATE))

def put_to_wav(frames: List[str], name: str):
  with wave.open(name, 'wb') as wave_file:
    wave_file.setnchannels(CHANNELS)
    wave_file.setsampwidth(pyaudio.get_sample_size(FORMAT))
    wave_file.setframerate(RATE)
    wave_file.writeframes(b''.join(frames))

if __name__ == '__main__':
  q = Queue()
  listener = Process(target=listen, args=(Microphone(), q))
  listener.start()
  print("Process started")
  frames = read_frames(q, [], 5)
  put_to_wav(frames, "out.wav")
  print("training")
  from classifier import train
  train(["out.wav"], [0])
  listener.terminate()
  print("Process ended")
